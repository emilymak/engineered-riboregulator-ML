{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sns.set_style('ticks', {'axes.grid': False, \n",
    "                        'grid.linestyle': '', \n",
    "                        'font.family':'sans-serif', \n",
    "                        'font.sans-serif':'Myriad Pro',\n",
    "                        'text.color': '0',\n",
    "                        'xtick.color': '0',\n",
    "                        'ytick.color': '0'\n",
    "                           })\n",
    "import umap\n",
    "\n",
    "sys.path.insert(1, '/work/06658/pramesh/maverick2/notebooks/')\n",
    "import NuSpeak_base as nuspeak\n",
    "\n",
    "from Bio import Seq, SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import FeatureLocation, CompoundLocation\n",
    "import networkx as nx\n",
    "from itertools import islice\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from random import sample\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.text.interpret import *\n",
    "from fastai.callbacks import *\n",
    "__all__ = ['OverSamplingCallback']\n",
    "\n",
    "# import look-ahead optimizer in lieu of Adam\n",
    "from ranger import Ranger\n",
    "optar = partial(Ranger)\n",
    "\n",
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import sklearn modules \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "path = Path('workdir/excels')\n",
    "path2 = Path('workdir/encoders')\n",
    "pltpath = 'workdir/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "n_trials = 5\n",
    "ngram_size = 3\n",
    "ngram_stride = 3\n",
    "embedding_size = 400\n",
    "test_frac = 0.10\n",
    "\n",
    "# define a tokenizer class that calls up Fastai's base tokenizer\n",
    "class GenomicConstantTokenizer2(BaseTokenizer):\n",
    "\n",
    "    def __init__(self, lang = 'en', kmer = ngram_size, stride = ngram_stride):\n",
    "        self.lang = lang\n",
    "        self.kmer = kmer\n",
    "        self.stride = stride\n",
    "\n",
    "    def tokenizer(self, t):\n",
    "        t = t.upper() # ensure all uppercase \n",
    "        if self.kmer == 1:\n",
    "            toks = list(t) # trivial case when the kmer is of length 1 \n",
    "        else:\n",
    "            toks = [t[i:i+self.kmer] for i in range(0, len(t), self.stride) if len(t[i:i+self.kmer]) == self.kmer]   \n",
    "        return toks # list of tokens \n",
    "    \n",
    "    def add_special_cases(self, toks):\n",
    "        pass\n",
    "\n",
    "def predict_prob(seq, learn_cf, learn_cr):\n",
    "    \"\"\"\n",
    "    This function predicts the probability of a sequence being a good toehold.\n",
    "    \n",
    "    Inputs:\n",
    "    seq: str - nucleic_acid\n",
    "    learn_cf: pretrained fastai forward classifier\n",
    "    learn_cr: pretrained fastai reverse classifier\n",
    "    \"\"\"\n",
    "    # convert to DNA if not already\n",
    "    seq = Seq(seq).back_transcribe().__str__().upper()\n",
    "    \n",
    "    _, _, arr_fwd = learn_cf.predict(seq)\n",
    "    _, _, arr_rev = learn_cr.predict(seq)\n",
    "    \n",
    "    avg_prob = (arr_fwd + arr_rev)/2 # average the forward and backwards probabilities \n",
    "    p1 = to_np(avg_prob)[1] # probability of being 'good'\n",
    "    return p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a series of random toeholds to serve as the base for the synthetic language model\n",
    "\n",
    "# convert the switches into toehold sensors given the switch sequence \n",
    "# and the start_codon and the rbs site \n",
    "def turn_switch_to_toehold(switch, rbs = 'AACAGAGGAGA', start_codon = 'ATG'):\n",
    "    stem1 = Seq(switch[24:30]).reverse_complement().__str__()\n",
    "    stem2 = Seq(switch[12:21]).reverse_complement().__str__()\n",
    "    toehold =  switch + rbs + stem1 + start_codon + stem2\n",
    "    return toehold\n",
    "\n",
    "# check for any stop codons that occur after the start and remove these from the pool \n",
    "## revised so that we only consider no in-frame stops \n",
    "def check_for_stop(toehold): \n",
    "    stop_codons = ['TAG', 'TAA', 'TGA']\n",
    "    bad_locations = [47, 50, 53, 56]\n",
    "    search = False\n",
    "    for stop in stop_codons:\n",
    "        for bad_loc in bad_locations:\n",
    "            stop_index = toehold.find(stop, bad_loc, bad_loc + 3) # val, start search, end search\n",
    "            search_test = stop_index == bad_loc\n",
    "            search = search | search_test\n",
    "    return search\n",
    "\n",
    "\n",
    "rand_switches = []\n",
    "for i in range(4*10**6):\n",
    "    temp = nuspeak.rand_seq(30)\n",
    "    rand_switches.append(temp)\n",
    "\n",
    "df_randLM = pd.DataFrame()\n",
    "df_randLM['switch'] = rand_switches\n",
    "df_randLM['min_toehold_sequence'] = df_randLM['switch'].apply(lambda x: turn_switch_to_toehold(x, rbs = 'AACAGAGGAGA', start_codon = 'ATG'))\n",
    "# we now have a dataframe of all possible toeholds\n",
    "start_codon = 'ATG'\n",
    "toeholds = df_randLM['min_toehold_sequence'].values.tolist()\n",
    "# remove all toeholds where there are start codons before the intended one starting at position 47\n",
    "no_start = [x for x in toeholds if x.index(start_codon) == 47]\n",
    "no_stop = [x for x in no_start if not check_for_stop(x)]\n",
    "\n",
    "# create a new dataframe of randomly generated toeholds for the LM training.\n",
    "df_randLM = pd.DataFrame()\n",
    "df_randLM['min_toehold_sequence'] = no_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>off_id</th>\n",
       "      <th>on_id</th>\n",
       "      <th>source_sequence</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>pre_seq</th>\n",
       "      <th>promoter</th>\n",
       "      <th>trigger</th>\n",
       "      <th>loop1</th>\n",
       "      <th>switch</th>\n",
       "      <th>loop2</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_onoff</th>\n",
       "      <th>on_qc</th>\n",
       "      <th>off_qc</th>\n",
       "      <th>delta_qc_onoff</th>\n",
       "      <th>min_toehold_sequence</th>\n",
       "      <th>ON/OFF quartile</th>\n",
       "      <th>Toehold Rating</th>\n",
       "      <th>scrambled_toehold</th>\n",
       "      <th>shufftok_toehold</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158012</th>\n",
       "      <td>AACCAAACACACAAACGCACGGGGGCTTGGTAATTCAACTACTGTC...</td>\n",
       "      <td>TCCGGACAGTAGTTGAATTACCAAGCCCCCAACCAAACACACAAAC...</td>\n",
       "      <td>random_sequences</td>\n",
       "      <td>random_sequence_38718</td>\n",
       "      <td>CTCTGGGCTAACTGTCGCGC</td>\n",
       "      <td>TAATACGACTCACTATAGGG</td>\n",
       "      <td>TCCGGACAGTAGTTGAATTACCAAGCCCCC</td>\n",
       "      <td>AACCAAACACACAAACGCAC</td>\n",
       "      <td>GGGGGCTTGGTAATTCAACTACTGTCCGGA</td>\n",
       "      <td>AACAGAGGAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>GGGGGCTTGGTAATTCAACTACTGTCCGGAAACAGAGGAGATCCGG...</td>\n",
       "      <td>25-50</td>\n",
       "      <td>Bad</td>\n",
       "      <td>ATCGTTTGCTAAAGTGCCGGGGACTAAAAACTGTCAGATTAAGTAA...</td>\n",
       "      <td>GGGGGAATCCGGGCGAATCCCTAGTAGGATTGAGTCAAAGAATTTG...</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48109</th>\n",
       "      <td>AACCAAACACACAAACGCACATGCAATCATTTATTCTCCTAGGTGA...</td>\n",
       "      <td>AAATTCACCTAGGAGAATAAATGATTGCATAACCAAACACACAAAC...</td>\n",
       "      <td>random_sequences</td>\n",
       "      <td>random_sequence_82399</td>\n",
       "      <td>CTCTGGGCTAACTGTCGCGC</td>\n",
       "      <td>TAATACGACTCACTATAGGG</td>\n",
       "      <td>AAATTCACCTAGGAGAATAAATGATTGCAT</td>\n",
       "      <td>AACCAAACACACAAACGCAC</td>\n",
       "      <td>ATGCAATCATTTATTCTCCTAGGTGAATTT</td>\n",
       "      <td>AACAGAGGAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058092</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ATGCAATCATTTATTCTCCTAGGTGAATTTAACAGAGGAGAAAATT...</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>Bad</td>\n",
       "      <td>GACATATTGTTAAGCTGCATACGGTAATCCAATAGATTTATAACTG...</td>\n",
       "      <td>AGAGGTAACTGTATAGGATTATGTTTGGACTCAATTTTCTATCAGA...</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199309</th>\n",
       "      <td>AACCAAACACACAAACGCACTCGGAAGGTAGTTTGTGACATACAGG...</td>\n",
       "      <td>CAAGCCTGTATGTCACAAACTACCTTCCGAAACCAAACACACAAAC...</td>\n",
       "      <td>random_sequences</td>\n",
       "      <td>random_sequence_77927</td>\n",
       "      <td>CTCTGGGCTAACTGTCGCGC</td>\n",
       "      <td>TAATACGACTCACTATAGGG</td>\n",
       "      <td>CAAGCCTGTATGTCACAAACTACCTTCCGA</td>\n",
       "      <td>AACCAAACACACAAACGCAC</td>\n",
       "      <td>TCGGAAGGTAGTTTGTGACATACAGGCTTG</td>\n",
       "      <td>AACAGAGGAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>TCGGAAGGTAGTTTGTGACATACAGGCTTGAACAGAGGAGACAAGC...</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>Bad</td>\n",
       "      <td>CCTAAACATGCGAGAGGAGATGATATGAAACGTCTTGTGAGACGAA...</td>\n",
       "      <td>GGATGTTCGAACGGTAACCATTGAGTGAAACAAGACATTTGGGCTG...</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185172</th>\n",
       "      <td>AACCAAACACACAAACGCACTAGTCATAATATTTCACTACCAGACT...</td>\n",
       "      <td>GTTGAGTCTGGTAGTGAAATATTATGACTAAACCAAACACACAAAC...</td>\n",
       "      <td>random_sequences</td>\n",
       "      <td>random_sequence_7124</td>\n",
       "      <td>CTCTGGGCTAACTGTCGCGC</td>\n",
       "      <td>TAATACGACTCACTATAGGG</td>\n",
       "      <td>GTTGAGTCTGGTAGTGAAATATTATGACTA</td>\n",
       "      <td>AACCAAACACACAAACGCAC</td>\n",
       "      <td>TAGTCATAATATTTCACTACCAGACTCAAC</td>\n",
       "      <td>AACAGAGGAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TAGTCATAATATTTCACTACCAGACTCAACAACAGAGGAGAGTTGA...</td>\n",
       "      <td>50-75</td>\n",
       "      <td>Bad</td>\n",
       "      <td>GGACTATAAATAGTCGTACACTAGCACTCTGAAACGGGGGCTAAAA...</td>\n",
       "      <td>AACGTGAGATATTTGAGATTCGGAACCAATGGCTCGAGTAATCAAC...</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180474</th>\n",
       "      <td>AACCAAACACACAAACGCACTAATTACCATCCGAGTGCTGCCATCA...</td>\n",
       "      <td>TCCGTGATGGCAGCACTCGGATGGTAATTAAACCAAACACACAAAC...</td>\n",
       "      <td>random_sequences</td>\n",
       "      <td>random_sequence_51555</td>\n",
       "      <td>CTCTGGGCTAACTGTCGCGC</td>\n",
       "      <td>TAATACGACTCACTATAGGG</td>\n",
       "      <td>TCCGTGATGGCAGCACTCGGATGGTAATTA</td>\n",
       "      <td>AACCAAACACACAAACGCAC</td>\n",
       "      <td>TAATTACCATCCGAGTGCTGCCATCACGGA</td>\n",
       "      <td>AACAGAGGAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TAATTACCATCCGAGTGCTGCCATCACGGAAACAGAGGAGATCCGT...</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>Bad</td>\n",
       "      <td>CGCTCGTTTAGGCATCAGATATGCTCGTGACCAGAGAGTAACCGCG...</td>\n",
       "      <td>CACTCCTGAAACGGACCACATGGAGATAGACAGCACTTATGCTGCT...</td>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   off_id  \\\n",
       "158012  AACCAAACACACAAACGCACGGGGGCTTGGTAATTCAACTACTGTC...   \n",
       "48109   AACCAAACACACAAACGCACATGCAATCATTTATTCTCCTAGGTGA...   \n",
       "199309  AACCAAACACACAAACGCACTCGGAAGGTAGTTTGTGACATACAGG...   \n",
       "185172  AACCAAACACACAAACGCACTAGTCATAATATTTCACTACCAGACT...   \n",
       "180474  AACCAAACACACAAACGCACTAATTACCATCCGAGTGCTGCCATCA...   \n",
       "\n",
       "                                                    on_id   source_sequence  \\\n",
       "158012  TCCGGACAGTAGTTGAATTACCAAGCCCCCAACCAAACACACAAAC...  random_sequences   \n",
       "48109   AAATTCACCTAGGAGAATAAATGATTGCATAACCAAACACACAAAC...  random_sequences   \n",
       "199309  CAAGCCTGTATGTCACAAACTACCTTCCGAAACCAAACACACAAAC...  random_sequences   \n",
       "185172  GTTGAGTCTGGTAGTGAAATATTATGACTAAACCAAACACACAAAC...  random_sequences   \n",
       "180474  TCCGTGATGGCAGCACTCGGATGGTAATTAAACCAAACACACAAAC...  random_sequences   \n",
       "\n",
       "                  sequence_id               pre_seq              promoter  \\\n",
       "158012  random_sequence_38718  CTCTGGGCTAACTGTCGCGC  TAATACGACTCACTATAGGG   \n",
       "48109   random_sequence_82399  CTCTGGGCTAACTGTCGCGC  TAATACGACTCACTATAGGG   \n",
       "199309  random_sequence_77927  CTCTGGGCTAACTGTCGCGC  TAATACGACTCACTATAGGG   \n",
       "185172   random_sequence_7124  CTCTGGGCTAACTGTCGCGC  TAATACGACTCACTATAGGG   \n",
       "180474  random_sequence_51555  CTCTGGGCTAACTGTCGCGC  TAATACGACTCACTATAGGG   \n",
       "\n",
       "                               trigger                 loop1  \\\n",
       "158012  TCCGGACAGTAGTTGAATTACCAAGCCCCC  AACCAAACACACAAACGCAC   \n",
       "48109   AAATTCACCTAGGAGAATAAATGATTGCAT  AACCAAACACACAAACGCAC   \n",
       "199309  CAAGCCTGTATGTCACAAACTACCTTCCGA  AACCAAACACACAAACGCAC   \n",
       "185172  GTTGAGTCTGGTAGTGAAATATTATGACTA  AACCAAACACACAAACGCAC   \n",
       "180474  TCCGTGATGGCAGCACTCGGATGGTAATTA  AACCAAACACACAAACGCAC   \n",
       "\n",
       "                                switch        loop2  ... delta_onoff on_qc  \\\n",
       "158012  GGGGGCTTGGTAATTCAACTACTGTCCGGA  AACAGAGGAGA  ...    0.078300   3.0   \n",
       "48109   ATGCAATCATTTATTCTCCTAGGTGAATTT  AACAGAGGAGA  ...    0.058092   3.0   \n",
       "199309  TCGGAAGGTAGTTTGTGACATACAGGCTTG  AACAGAGGAGA  ...    0.000000   1.1   \n",
       "185172  TAGTCATAATATTTCACTACCAGACTCAAC  AACAGAGGAGA  ...    0.460785   2.0   \n",
       "180474  TAATTACCATCCGAGTGCTGCCATCACGGA  AACAGAGGAGA  ...    0.001111   2.0   \n",
       "\n",
       "       off_qc delta_qc_onoff  \\\n",
       "158012    1.1            1.1   \n",
       "48109     2.0            2.0   \n",
       "199309    1.1            1.1   \n",
       "185172    2.0            2.0   \n",
       "180474    3.0            2.0   \n",
       "\n",
       "                                     min_toehold_sequence  ON/OFF quartile  \\\n",
       "158012  GGGGGCTTGGTAATTCAACTACTGTCCGGAAACAGAGGAGATCCGG...            25-50   \n",
       "48109   ATGCAATCATTTATTCTCCTAGGTGAATTTAACAGAGGAGAAAATT...           Bottom   \n",
       "199309  TCGGAAGGTAGTTTGTGACATACAGGCTTGAACAGAGGAGACAAGC...           Bottom   \n",
       "185172  TAGTCATAATATTTCACTACCAGACTCAACAACAGAGGAGAGTTGA...            50-75   \n",
       "180474  TAATTACCATCCGAGTGCTGCCATCACGGAAACAGAGGAGATCCGT...           Bottom   \n",
       "\n",
       "        Toehold Rating                                  scrambled_toehold  \\\n",
       "158012             Bad  ATCGTTTGCTAAAGTGCCGGGGACTAAAAACTGTCAGATTAAGTAA...   \n",
       "48109              Bad  GACATATTGTTAAGCTGCATACGGTAATCCAATAGATTTATAACTG...   \n",
       "199309             Bad  CCTAAACATGCGAGAGGAGATGATATGAAACGTCTTGTGAGACGAA...   \n",
       "185172             Bad  GGACTATAAATAGTCGTACACTAGCACTCTGAAACGGGGGCTAAAA...   \n",
       "180474             Bad  CGCTCGTTTAGGCATCAGATATGCTCGTGACCAGAGAGTAACCGCG...   \n",
       "\n",
       "                                         shufftok_toehold   class  \n",
       "158012  GGGGGAATCCGGGCGAATCCCTAGTAGGATTGAGTCAAAGAATTTG...  random  \n",
       "48109   AGAGGTAACTGTATAGGATTATGTTTGGACTCAATTTTCTATCAGA...  random  \n",
       "199309  GGATGTTCGAACGGTAACCATTGAGTGAAACAAGACATTTGGGCTG...  random  \n",
       "185172  AACGTGAGATATTTGAGATTCGGAACCAATGGCTCGAGTAATCAAC...  random  \n",
       "180474  CACTCCTGAAACGGACCACATGGAGATAGACAGCACTTATGCTGCT...  random  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the toehold dataset and preprocess for ML to create a df for classification\n",
    "# based on the ON/OFF ratios of the sensors\n",
    "\n",
    "df = pd.read_csv(path/'newQC_toehold_data.csv', comment = '#')\n",
    "\n",
    "# rename the columns \n",
    "rename_dict = {\n",
    "    \"Unnamed: 0\" : \"toehold_id\",\n",
    "    \"onoff_value\" : \"delta_onoff\",\n",
    "    \"onoff_qc\" : \"delta_qc_onoff\",\n",
    "    \"switch_sequence\" : \"min_toehold_sequence\"\n",
    "}\n",
    "\n",
    "# clean up df to get rid of NaN and low qc reads \n",
    "df = df.rename(columns = rename_dict)\n",
    "df = df.dropna() # throw out nan's \n",
    "ngs_qc_onind = df['on_qc'] >= 1.1 # keep all the acceptable reads for the ON\n",
    "ngs_qc_offind = df['off_qc'] >= 1.1 # keep all the acceptable reads for the OFF\n",
    "df = df.loc[ngs_qc_onind & ngs_qc_offind, :]\n",
    "\n",
    "# bin the toeholds by their ON/OFF ratio into quartlies for the classifier \n",
    "df['ON/OFF quartile'] = pd.qcut(df['delta_onoff'], \n",
    "                                      q = 4, \n",
    "                                      labels = ['Bottom', '25-50', '50-75', 'Top',\n",
    "                                               ])\n",
    "\n",
    "ind_top = df['ON/OFF quartile'] == 'Top' # find the top 25% of toeholds\n",
    "ind_bottom = df['ON/OFF quartile'] != 'Top' # find the bottom 75% of toeholds\n",
    "df_best_toeholds = df.loc[ind_top, :] # slice out the top 25%\n",
    "df_bad_toeholds = df.loc[ind_bottom, :] # slice out the bottom 75%\n",
    "\n",
    "df_best_toeholds['Toehold Rating'] = 'Good'\n",
    "df_bad_toeholds['Toehold Rating'] = 'Bad'\n",
    "df_classify = pd.concat([df_best_toeholds, df_bad_toeholds], axis = 0)\n",
    "df_classify['scrambled_toehold'] = df_classify['min_toehold_sequence'].apply(lambda x: nuspeak.seq_scrambler(x))\n",
    "df_classify['shufftok_toehold'] = df_classify['min_toehold_sequence'].apply(lambda x: nuspeak.sent_scrambler(seq = x, \n",
    "                                                                                       ngram_size = ngram_size, \n",
    "                                                                                       ngram_stride = ngram_stride))\n",
    "df_classify = df_classify.sample(frac = 1).reindex() \n",
    "# find all random sequences \n",
    "substring1 = 'random'\n",
    "df_classify['indices'] = df_classify['sequence_id'].str.find(substring1)\n",
    "ind = df_classify['indices'] >= 0\n",
    "ind2 = df_classify['indices'] < 0\n",
    "\n",
    "df_random = df_classify.loc[ind,:]\n",
    "df_random['class'] = 'random'\n",
    "df_random = df_random.drop('indices', axis = 1)\n",
    "\n",
    "df_classify = df_classify.loc[ind2,:]\n",
    "df_classify = df_classify.drop('indices', axis = 1)\n",
    "\n",
    "# find all human_tf sequences \n",
    "substring2 = 'human'\n",
    "df_classify['indices'] = df_classify['sequence_id'].str.find(substring2)\n",
    "ind = df_classify['indices'] >= 0\n",
    "ind2 = df_classify['indices'] < 0\n",
    "\n",
    "df_human = df_classify.loc[ind,:]\n",
    "df_human['class'] = 'human'\n",
    "df_human = df_human.drop('indices', axis = 1)\n",
    "\n",
    "df_classify = df_classify.loc[ind2,:]\n",
    "df_classify = df_classify.drop('indices', axis = 1)\n",
    "\n",
    "# the rest are all viral sequences \n",
    "df_viral = df_classify\n",
    "df_viral['class'] = 'viral'\n",
    "\n",
    "df_classify = pd.concat([df_random, df_human, df_viral], axis = 0)\n",
    "df_classify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/opt/apps/cuda/10.0'\n"
     ]
    }
   ],
   "source": [
    "# lets create the training and validation sets for the random toehold lM\n",
    "valid_df, train_df = nuspeak.split_gendata(df_randLM, test_frac)\n",
    "train_df['is_train'] = 1\n",
    "valid_df['is_train'] = 0\n",
    "\n",
    "tokenizer = Tokenizer(tok_func = GenomicConstantTokenizer2, \n",
    "                      pre_rules = [], post_rules = [],\n",
    "                      special_cases = ['xxpad'])\n",
    "\n",
    "\n",
    "# forward language \n",
    "toehold_LMf = nuspeak.GenomicTextLMDataBunch.from_df(path = path, train_df = train_df, valid_df = valid_df,\n",
    "                                                   tokenizer = tokenizer, text_cols = 'min_toehold_sequence', \n",
    "                                                  label_cols = 1, bs = 128, backwards = False, bptt = 25) # create a forward language model \n",
    "# reverse language\n",
    "toehold_LMr = nuspeak.GenomicTextLMDataBunch.from_df(path = path, train_df = train_df, valid_df = valid_df,\n",
    "                                                   tokenizer = tokenizer, text_cols = 'min_toehold_sequence', \n",
    "                                                  label_cols = 1, bs = 128, backwards = True, bptt = 25) # create a backwards language model\n",
    "config_fwd = dict(emb_sz = embedding_size, \n",
    "              n_hid = 1552, \n",
    "              n_layers = 4, \n",
    "              pad_token = 0, \n",
    "              qrnn = True,\n",
    "              bidir = False, \n",
    "              output_p = 0.2, \n",
    "              hidden_p = 0.20, \n",
    "              input_p = 0.30, \n",
    "              embed_p = 0.1, \n",
    "              weight_p = 0.25, \n",
    "              tie_weights = True, \n",
    "              out_bias = True)\n",
    "\n",
    "config_rev = dict(emb_sz = embedding_size, \n",
    "              n_hid = 1552, \n",
    "              n_layers = 4, \n",
    "              pad_token = 0, \n",
    "              qrnn = True,\n",
    "              bidir = False, \n",
    "              output_p = 0.2, \n",
    "              hidden_p = 0.20, \n",
    "              input_p = 0.30, \n",
    "              embed_p = 0.1, \n",
    "              weight_p = 0.25, \n",
    "              tie_weights = True, \n",
    "              out_bias = True)\n",
    "\n",
    "\n",
    "classify_config = dict(\n",
    "    emb_sz = embedding_size,\n",
    "    n_hid = 1552, # multiply by two to account for bidirectionality if True\n",
    "    n_layers = 4,\n",
    "    pad_token = 0,\n",
    "    qrnn = True,\n",
    "    bidir = False,\n",
    "    output_p = 0.5, # standard dropout applied to activations in the linear head\n",
    ")\n",
    "\n",
    "drop_mult = 1.0 # multiplier across all dropouts \n",
    "wd = 0.1 # strong l2 regularization\n",
    "\n",
    "# initialize the language model learners \n",
    "learn_fwd = nuspeak.NuSpeak_learner(data = toehold_LMf, \n",
    "                                      arch = AWD_LSTM, \n",
    "                                      config = config_fwd, \n",
    "                                      drop_mult = drop_mult, \n",
    "                                      wd = wd)\n",
    "\n",
    "learn_rev = nuspeak.NuSpeak_learner(data = toehold_LMr, \n",
    "                                      arch = AWD_LSTM, \n",
    "                                      config = config_rev, \n",
    "                                      drop_mult = drop_mult, \n",
    "                                      wd = wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the vocabs from the language models \n",
    "np.save(path2/'toehold_LMf_vocab.npy', toehold_LMf.vocab.itos)\n",
    "np.save(path2/'toehold_LMr_vocab.npy', toehold_LMr.vocab.itos)\n",
    "\n",
    "# train the forward model \n",
    "learn_fwd.unfreeze()\n",
    "schedf = nuspeak.FlatCosAnnealScheduler(learn_fwd, lr = 5e-3, tot_epochs = 15, moms = (0.8, 0.7));\n",
    "learn_fwd.callbacks.append(schedf)\n",
    "learn_fwd.fit(15)\n",
    "learn_fwd.save('toe_LMf')\n",
    "learn_fwd.save_encoder('toe_LMf_enc')\n",
    "\n",
    "# train the reverse model \n",
    "learn_rev.unfreeze()\n",
    "schedr = nuspeak.FlatCosAnnealScheduler(learn_rev, lr = 5e-3, tot_epochs = 15, moms = (0.8, 0.7));\n",
    "learn_rev.callbacks.append(schedr)\n",
    "learn_rev.fit(15)\n",
    "learn_rev.save('toe_LMr')\n",
    "learn_rev.save_encoder('toe_LMr_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the respective vocabs\n",
    "voc_fwd = np.load(path2/'toehold_LMf_vocab.npy')\n",
    "voc_rev = np.load(path2/'toehold_LMr_vocab.npy')\n",
    "fwd_model_vocab = nuspeak.GenomicVocab(voc_fwd)\n",
    "rev_model_vocab = nuspeak.GenomicVocab(voc_rev)\n",
    "\n",
    "# load the saved language models if pretrained\n",
    "learn_fwd = learn_fwd.load('toe_LMf');\n",
    "learn_rev = learn_rev.load('toe_LMr');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_targets = df_classify['Toehold Rating']\n",
    "X_samples = df_classify.drop('Toehold Rating', axis = 1)\n",
    "\n",
    "scores = []\n",
    "aucs = []\n",
    "fracs = []\n",
    "mccs = []\n",
    "mccs_c1 = []\n",
    "mccs_c2 = []\n",
    "c1_scores = [] # for the control shuffled tokens\n",
    "c2_scores = [] # for the control shuffled characters\n",
    "tprs = []\n",
    "aucs = []\n",
    "\n",
    "# first prepare the dataset for testing\n",
    "X_withheld, X_test, y_withheld, y_test = train_test_split(X_samples, \n",
    "                                                            y_targets, \n",
    "                                                            train_size = 1 - test_frac, \n",
    "                                                            shuffle = True, \n",
    "                                                            stratify = y_targets)\n",
    "        \n",
    "# now partition the remainder for testing and validation \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_withheld, \n",
    "                                                    y_withheld, \n",
    "                                                    train_size = 1 - test_frac, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify = y_withheld)\n",
    "            \n",
    "df_train = pd.concat([X_train, y_train], axis = 1)\n",
    "df_train['set'] = 'train'\n",
    "        \n",
    "df_valid = pd.concat([X_valid, y_valid], axis = 1)\n",
    "df_valid['set'] = 'valid'\n",
    "        \n",
    "df_test = pd.concat([X_test, y_test], axis = 1)\n",
    "df_test['set'] = 'test'\n",
    "        \n",
    "toehold_df = pd.concat([df_train, df_valid], axis = 0)\n",
    "toehold_df = toehold_df.sample(frac = 1).reindex() # shuffle up\n",
    "        \n",
    "\n",
    "# create a databunch for feeding into the NLP routine using the same tokenizer as the language model \n",
    "toehold_dbf = nuspeak.GenomicTextClasDataBunch.from_df(path = path, train_df = df_train, valid_df = df_valid,\n",
    "                                                test_df = df_test, tokenizer = tokenizer, vocab = fwd_model_vocab,\n",
    "                                                text_cols = 'min_toehold_sequence', label_cols = 'Toehold Rating',\n",
    "                                                bs = 128, backwards = False)\n",
    "\n",
    "toehold_dbr = nuspeak.GenomicTextClasDataBunch.from_df(path = path, train_df = df_train, valid_df = df_valid,\n",
    "                                                test_df = df_test, tokenizer = tokenizer, vocab = rev_model_vocab,\n",
    "                                                text_cols = 'min_toehold_sequence', label_cols = 'Toehold Rating',\n",
    "                                                bs = 128, backwards = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cf = nuspeak.NuSpeak_classifier_learner(data = toehold_dbf, \n",
    "                                               arch = AWD_LSTM, \n",
    "                                               config = classify_config, \n",
    "                                               drop_mult = drop_mult,\n",
    "                                               clip = None, wd = 0.1, bptt = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not trained, run this section\n",
    "learn_cf.load_encoder('/work/06658/pramesh/maverick2/excels/models/toe_LMf_enc')\n",
    "learn_cf.fit_one_cycle(9, max_lr = 5e-2)\n",
    "        \n",
    "learn_cf.freeze_to(-2)\n",
    "learn_cf.fit_one_cycle(5, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.95))\n",
    "        \n",
    "learn_cf.freeze_to(-3)\n",
    "learn_cf.fit_one_cycle(5, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.95))\n",
    "        \n",
    "learn_cf.unfreeze()\n",
    "learn_cf.fit_one_cycle(8, max_lr = 2.5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classify_testf = nuspeak.GenomicTextClasDataBunch.from_df(path = path, train_df = df_train, valid_df = df_test,\n",
    "                                                tokenizer = tokenizer, vocab = fwd_model_vocab,\n",
    "                                                text_cols = 'min_toehold_sequence', label_cols = 'Toehold Rating',\n",
    "                                                bs = 128, backwards = False)\n",
    "# assign this data to the trained learner \n",
    "learn_cf.data = data_classify_testf\n",
    "# compute metrics \n",
    "preds, _, _ = learn_cf.get_preds(ordered = True, with_loss = True)\n",
    "roc_aucf = roc_auc_score(df_test['Toehold Rating'], preds[:,1])\n",
    "acuf, mccf = nuspeak.get_metrics(learn_cf, return_metrics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cr = dulm.dna_classifier_learner(data = toehold_dbr, \n",
    "                                               arch = AWD_LSTM, \n",
    "                                               config = classify_config, \n",
    "                                               drop_mult = drop_mult,\n",
    "                                               clip = None, wd = 0.1, bptt = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_cr.load_encoder('/work/06658/pramesh/maverick2/excels/models/toe_LMr_enc')\n",
    "learn_cr.fit_one_cycle(9, max_lr = 5e-2)\n",
    "        \n",
    "learn_cr.freeze_to(-2)\n",
    "learn_cr.fit_one_cycle(5, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.95))\n",
    "        \n",
    "learn_cr.freeze_to(-3)\n",
    "learn_cr.fit_one_cycle(5, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.95))\n",
    "        \n",
    "learn_cr.unfreeze()\n",
    "learn_cr.fit_one_cycle(8, max_lr = 2.5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the test set data bunch\n",
    "data_classify_testr = dulm.GenomicTextClasDataBunch.from_df(path = path, train_df = df_train, valid_df = df_test,\n",
    "                                                tokenizer = tokenizer, vocab = rev_model_vocab,\n",
    "                                                text_cols = 'min_toehold_sequence', label_cols = 'Toehold Rating',\n",
    "                                                bs = 128, backwards = True)\n",
    "# assign this data to the trained learner \n",
    "learn_cr.data = data_classify_testr\n",
    "# compute metrics \n",
    "preds, _, _ = learn_cr.get_preds(ordered = True, with_loss = True)\n",
    "roc_aucr = roc_auc_score(df_test['Toehold Rating'], preds[:,1])\n",
    "acur, mccr = nuspeak.get_metrics(learn_cr, return_metrics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the confusion matrix on the test set for the forward classifier\n",
    "interp = ClassificationInterpretation.from_learner(learn_cf)\n",
    "interp.plot_confusion_matrix(title = 'Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the confusion matrix on the test set for the backwards classifier\n",
    "interp = ClassificationInterpretation.from_learner(learn_cr)\n",
    "interp.plot_confusion_matrix(title = 'Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to calculate the intrinsic self-attention for each sequence in the test-set as seen by \n",
    "# the pre-trained models.\n",
    "\n",
    "# ensemble the predictions for the two classifiers\n",
    "pred_fwd, _, _ = learn_cf.get_preds(ordered = True, with_loss = True)\n",
    "pred_rev, _, _ = learn_cr.get_preds(ordered = True, with_loss = True)\n",
    "final_pred = (pred_fwd + pred_rev)/2 #take the average of the two models\n",
    "\n",
    "testdf_compiled = pd.DataFrame()\n",
    "testdf_compiled[df_test.columns.values.tolist()] = df_test[df_test.columns.values.tolist()]\n",
    "testdf_compiled['prob_cat0'] = to_np(final_pred[:,0]) # the probabilities for class 0 are in column 0\n",
    "testdf_compiled['prob_cat1'] = to_np(final_pred[:,1]) # the probabilities for class 1 are in column 1\n",
    "\n",
    "# we want to remove all the false positives and negatives in this dataset \n",
    "ind_true_bad = (testdf_compiled['prob_cat0'] > 0.50) & (testdf_compiled['Toehold Rating'] == 'Bad')\n",
    "true_bad = testdf_compiled.loc[ind_true_bad, :]\n",
    "\n",
    "ind_true_good = (testdf_compiled['prob_cat1'] > 0.50) & (testdf_compiled['Toehold Rating'] == 'Good') \n",
    "true_good = testdf_compiled.loc[ind_true_good, :]\n",
    "# stitch together into a dataframe of true positives and true negatives\n",
    "testdf_true_compiled = pd.concat([true_good, true_bad], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# self-attention in the forward direction\n",
    "txt_ci = TextClassificationInterpretation.from_learner(learn_cf)\n",
    "seqs = testdf_true_compiled['min_toehold_sequence'].values.tolist()\n",
    "\n",
    "fwd_attns = []\n",
    "for seq in seqs:\n",
    "    _, attn = txt_ci.intrinsic_attention(seq)\n",
    "    intattn = to_np(attn)\n",
    "    fwd_attns.append(intattn)\n",
    "    \n",
    "df_fwd_attn = pd.DataFrame(fwd_attns)\n",
    "\n",
    "\n",
    "txt_ci = TextClassificationInterpretation.from_learner(learn_cr)\n",
    "rev_attns = []\n",
    "\n",
    "for seq in seqs:\n",
    "    _, attn = txt_ci.intrinsic_attention(seq)\n",
    "    intattn = to_np(attn)\n",
    "    rev_attns.append(intattn)\n",
    "df_allrevattn = pd.DataFrame(rev_attns)\n",
    "\n",
    "\n",
    "# df_fwd_attn and df_allrevattn now contain the intrinsic attention as seen by the model for each sequence\n",
    "# we can ensemble them and plot them as a function of nucleotide position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize learned language model embeddings use the following code\n",
    "# the same can be done for any pre-trained fastai learner.\n",
    "\n",
    "# first randomly subsample the test set to create a list of sequences\n",
    "df_vis = df_test.sample(frac = .1)\n",
    "\n",
    "# make a list of sequences to be visualized\n",
    "seqs = df_vis['min_toehold_sequence'].values.tolist()\n",
    "\n",
    "encodings_seqsf = []\n",
    "encodings_seqsr = []\n",
    "for seq in seqs:\n",
    "    arr_lmf = nuspeak.encode_doc3(learn = learn_fwd, doc = seq)\n",
    "    arr_lmr = nuspeak.encode_doc3(learn = learn_rev, doc = seq)\n",
    "    encodings_seqsf.append(arr_lmf)\n",
    "    encodings_seqsr.append(arr_lmr)\n",
    "# we now have two arrays of the averaged hidden representation     \n",
    "doc2vec_contf = pd.DataFrame(encodings_seqsf)\n",
    "doc2vec_contf.index = df_vis.index \n",
    "\n",
    "doc2vec_contr = pd.DataFrame(encodings_seqsr)\n",
    "doc2vec_contr.index = df_vis.index \n",
    "\n",
    "# ensemble the hidden representations for the forwards and backwards directions \n",
    "doc2vec_ensemb = 0.5*(doc2vec_contf + doc2vec_contr)\n",
    "# use UMAP to transform onto a 2D plane\n",
    "transform_ensemb = umap.UMAP(n_neighbors = 4, metric = 'cosine', n_components = 2).fit_transform(doc2vec_ensemb)\n",
    "\n",
    "# plot \n",
    "labels_f = df_vis['Toehold Rating'].values.tolist()\n",
    "umap_transformed_cont = pd.DataFrame()\n",
    "umap_transformed_cont['d1'] = transform_ensemb[:,0]\n",
    "umap_transformed_cont['d2'] = transform_ensemb[:,1]\n",
    "umap_transformed_cont['Class'] = labels_f\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "ax = sns.scatterplot(x = 'd1', y = 'd2', data = umap_transformed_cont, \n",
    "                     hue = 'Class', legend = 'full', alpha = 0.5,\n",
    "                     )\n",
    "ax.set_xlabel('UMAP $d_1$')\n",
    "ax.set_ylabel('UMAP $d_2$')\n",
    "ax.legend(loc='center left', bbox_to_anchor = (1, 0.5),\n",
    "          ncol = 1, fancybox = False, shadow = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variants(toehold_seq):\n",
    "    \"\"\"\n",
    "    This function generates all possible unique variants of the ascending stem of a switch\n",
    "    and generates the corresponding toehold.\n",
    "    \n",
    "    Inputs:\n",
    "    toehold_seq: str - nucleic-acid\n",
    "    \"\"\"\n",
    "    # convert to DNA and upper case if not already\n",
    "    toehold_seq = Seq(toehold_seq).back_transcribe().__str__().upper()\n",
    "    p1 = [toehold_seq[:21]] * (4**9) # keep the first 21nt of the sensing region the same and repeat 4**9 \n",
    "    p2 = [''.join(i) for i in product('ATCG', repeat = 9)] # make all permutations of 9 nt\n",
    "    p3 = [i + j for (i, j) in zip(p1, p2)] # sum the two lists \n",
    "    \n",
    "    p4 = [turn_switch_to_toehold(s, rbs = 'AACAGAGGAGA', start_codon = 'ATG') for s in p3]\n",
    "    start_codon = 'ATG'\n",
    "    # remove all toeholds where there are start codons before the intended one starting at position 47\n",
    "    no_start = [x for x in p4 if x.index(start_codon) == 47]\n",
    "    no_stop = [x for x in no_start if not check_for_stop(x)]\n",
    "    \n",
    "    p5 = [x[:30] for x in no_stop]\n",
    "    p6 = [Seq(s).reverse_complement().__str__().upper() for s in p5]\n",
    "    \n",
    "    df_var = pd.DataFrame()\n",
    "    df_var['trigger'] = p6\n",
    "    df_var['switch'] = p5\n",
    "    df_var['min_toehold_sequence'] = no_stop\n",
    "    \n",
    "    return df_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate specific toeholds to be optimized\n",
    "covid_toeholds = [\n",
    "    'CACGCACAGAATTTTGAGCAGTTTCAAGAGAACAGAGGAGACTCTTGATGCTGCTCAAA',\n",
    "    'AGCTGTCCAACCTGAAGAAGAATCACCAGGAACAGAGGAGACCTGGTATGTCTTCTTCA',\n",
    "    'GCTGTCCAACCTGAAGAAGAATCACCAGGAAACAGAGGAGATCCTGGATGTTCTTCTTC',\n",
    "    'CTGTCCAACCTGAAGAAGAATCACCAGGAGAACAGAGGAGACTCCTGATGATTCTTCTT',\n",
    "    'CTGTAATGGTTCCATTTTCATTATATTTTAAACAGAGGAGATAAAATATGATGAAAATG',\n",
    "    'GGTTCCATTTTCATTATATTTTAATAGAAAAACAGAGGAGATTTCTAATGAAATATAAT',\n",
    "    'GTATTGTTATAGCGGCCTTCTGTAAAACACAACAGAGGAGAGTGTTTATGAGAAGGCCG',\n",
    "    'CATAGCATCAATGAGTCTCAGTGAATACTGAACAGAGGAGACAGTATATGCTGAGACTC',\n",
    "    'TTTTAATAGAAAAGTCCTAGGTTGAAGATAAACAGAGGAGATATCTTATGCCTAGGACT',\n",
    "    'GGCCTTCTGTAAAACACGCACAGAATTTTGAACAGAGGAGACAAAATATGGTGCGTGTT',\n",
    "    'CCTAGGTTGAAGATAACCCACATAATAAGCAACAGAGGAGAGCTTATATGGTGGGTTAT',\n",
    "    'TGTTAGTAGCCAAATCAGATGTGAACATCAAACAGAGGAGATGATGTATGCATCTGATT',\n",
    "]\n",
    "\n",
    "# generate a dataframe of all possible variants\n",
    "df_var = pd.DataFrame()\n",
    "for toehold in covid_toeholds:\n",
    "    temp = generate_variants(toehold_seq = toehold)\n",
    "    df_var = pd.concat([df_var, temp], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigger</th>\n",
       "      <th>switch</th>\n",
       "      <th>min_toehold_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTTTTTTTTCTGCTCAAAATTCTGTGCGTG</td>\n",
       "      <td>CACGCACAGAATTTTGAGCAGAAAAAAAAA</td>\n",
       "      <td>CACGCACAGAATTTTGAGCAGAAAAAAAAAAACAGAGGAGATTTTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATTTTTTTTCTGCTCAAAATTCTGTGCGTG</td>\n",
       "      <td>CACGCACAGAATTTTGAGCAGAAAAAAAAT</td>\n",
       "      <td>CACGCACAGAATTTTGAGCAGAAAAAAAATAACAGAGGAGAATTTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GTTTTTTTTCTGCTCAAAATTCTGTGCGTG</td>\n",
       "      <td>CACGCACAGAATTTTGAGCAGAAAAAAAAC</td>\n",
       "      <td>CACGCACAGAATTTTGAGCAGAAAAAAAACAACAGAGGAGAGTTTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTTTTTTTTCTGCTCAAAATTCTGTGCGTG</td>\n",
       "      <td>CACGCACAGAATTTTGAGCAGAAAAAAAAG</td>\n",
       "      <td>CACGCACAGAATTTTGAGCAGAAAAAAAAGAACAGAGGAGACTTTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TATTTTTTTCTGCTCAAAATTCTGTGCGTG</td>\n",
       "      <td>CACGCACAGAATTTTGAGCAGAAAAAAATA</td>\n",
       "      <td>CACGCACAGAATTTTGAGCAGAAAAAAATAAACAGAGGAGATATTT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          trigger                          switch  \\\n",
       "0  TTTTTTTTTCTGCTCAAAATTCTGTGCGTG  CACGCACAGAATTTTGAGCAGAAAAAAAAA   \n",
       "1  ATTTTTTTTCTGCTCAAAATTCTGTGCGTG  CACGCACAGAATTTTGAGCAGAAAAAAAAT   \n",
       "2  GTTTTTTTTCTGCTCAAAATTCTGTGCGTG  CACGCACAGAATTTTGAGCAGAAAAAAAAC   \n",
       "3  CTTTTTTTTCTGCTCAAAATTCTGTGCGTG  CACGCACAGAATTTTGAGCAGAAAAAAAAG   \n",
       "4  TATTTTTTTCTGCTCAAAATTCTGTGCGTG  CACGCACAGAATTTTGAGCAGAAAAAAATA   \n",
       "\n",
       "                                min_toehold_sequence  \n",
       "0  CACGCACAGAATTTTGAGCAGAAAAAAAAAAACAGAGGAGATTTTT...  \n",
       "1  CACGCACAGAATTTTGAGCAGAAAAAAAATAACAGAGGAGAATTTT...  \n",
       "2  CACGCACAGAATTTTGAGCAGAAAAAAAACAACAGAGGAGAGTTTT...  \n",
       "3  CACGCACAGAATTTTGAGCAGAAAAAAAAGAACAGAGGAGACTTTT...  \n",
       "4  CACGCACAGAATTTTGAGCAGAAAAAAATAAACAGAGGAGATATTT...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a long time since we have a lot of variants.\n",
    "# go through and decide the probability of all variants; we can select by the probability or confidence that a sequence is in the top25%\n",
    "df_var['prob good'] = df_var['min_toehold_sequence'].apply(lambda x: predict_prob(x, learn_cf = learn_cf, learn_cr = learn_cr))\n",
    "df_var['prob bad'] = 1 - df_var['prob good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
