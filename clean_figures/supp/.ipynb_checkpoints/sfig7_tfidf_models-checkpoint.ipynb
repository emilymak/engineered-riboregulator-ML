{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules to import \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "# this to set the plot styles \n",
    "sns.set_context('paper', font_scale = 1.5, rc = {\"lines.linewidth\": 1.5})\n",
    "sns.set_style('ticks', {'axes.grid': False, \n",
    "                        'grid.linestyle': '', \n",
    "                        'font.family':'sans-serif', \n",
    "                        'font.sans-serif':'Myriad Pro',\n",
    "                        'text.color': '0',\n",
    "                        'xtick.color': '0',\n",
    "                        'ytick.color': '0'\n",
    "                           })\n",
    "\n",
    "from Bio import Seq, SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import FeatureLocation, CompoundLocation\n",
    "import networkx as nx\n",
    "from itertools import islice\n",
    "import re\n",
    "import random\n",
    "\n",
    "# import sklearn modules \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV, learning_curve, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, make_scorer\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the toehold dataset and preprocess for ML \n",
    "df = pd.read_csv('../../data/newQC_toehold_data.csv', comment = '#')\n",
    "\n",
    "# rename the columns \n",
    "rename_dict = {\n",
    "    \"Unnamed: 0\" : \"toehold_id\",\n",
    "    \"onoff_value\" : \"delta_onoff\",\n",
    "    \"onoff_qc\" : \"delta_qc_onoff\",\n",
    "    \"switch_sequence\" : \"min_toehold_sequence\"\n",
    "}\n",
    "\n",
    "# clean up df to get rid of NaN and low qc reads \n",
    "df = df.rename(columns = rename_dict)\n",
    "df = df.dropna() # throw out nan's \n",
    "\n",
    "ngs_qc_onind = df['on_qc'] >= 1.1 # keep all the acceptable reads for the ON\n",
    "ngs_qc_offind = df['off_qc'] >= 1.1 # keep all the acceptable reads for the OFF\n",
    "df = df.loc[ngs_qc_onind & ngs_qc_offind, :]\n",
    "\n",
    "# bin the toeholds by their ON/OFF ratio into quartlies  \n",
    "df['toehold_quartile'] = pd.qcut(df['delta_onoff'], q = 4, labels = ['worst', 'q2', 'q3', 'best'])\n",
    "\n",
    "# slice out the top 25% and bottom 75%\n",
    "df_top = df[df['toehold_quartile'] == 'best']\n",
    "\n",
    "df_bottom = df[df['toehold_quartile'] != 'best']\n",
    "df_bottom['toehold_quartile'] = 'worst'\n",
    "\n",
    "df_classify = pd.concat([df_top, df_bottom], axis = 0)\n",
    "\n",
    "# instantiate the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "df_classify['quartile_rating'] = label_encoder.fit_transform(df_classify['toehold_quartile'])\n",
    "df_classify = df_classify.sample(frac = 1)\n",
    "df_classify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to tokenize DNA and produce a 'sentence' of k-mer tokens \n",
    "def tokenize_dna(seq, ngram_size, ngram_stride):\n",
    "    \"\"\"\n",
    "    Function to break up a DNA sequence into kmers\n",
    "    \n",
    "    Inputs:\n",
    "    seq: str\n",
    "    ngram_size: int\n",
    "    ngram_stride: int\n",
    "    \"\"\"\n",
    "    if ngram_size == 1:\n",
    "        toks = list(seq) # for character level encoding of a dna sequence\n",
    "    else:\n",
    "        toks = [seq[i:i+ngram_size] for i in range(0, len(seq), ngram_stride)]\n",
    "    return toks\n",
    "\n",
    "# stitch the tokens together into a sentence \n",
    "def seq_sentence(seq, ngram_size, ngram_stride):\n",
    "    \"\"\"\n",
    "    Function that stitches together DNA kmers into a sentence\n",
    "    \n",
    "    Inputs:\n",
    "    seq: str\n",
    "    ngram_size: int\n",
    "    ngram_stride: int\n",
    "    \"\"\"\n",
    "    toks = tokenize_dna(seq = seq, ngram_size = ngram_size, ngram_stride = ngram_stride)\n",
    "    seq_sentence = ' '.join(toks)\n",
    "    \n",
    "    return seq_sentence\n",
    "\n",
    "def seq_scrambler(seq):\n",
    "    \"\"\" \n",
    "    Return the scrambled sequence of an input sequence. Ensures that the scrambled output returned has the same letter frequency\n",
    "    but in a different order than the original sequence. Negative control for all models.\n",
    "        \n",
    "    Inputs:\n",
    "    seq: str\n",
    "    \"\"\"\n",
    "    scrambled_sequence = seq\n",
    "\n",
    "    if len(set(seq)) == 1:\n",
    "        return scrambled_sequence\n",
    "    else:\n",
    "        while scrambled_sequence == seq:\n",
    "            chars = list(seq)\n",
    "            random.shuffle(chars)\n",
    "            scrambled_sequence = ''.join(chars)\n",
    "    return scrambled_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test to show that seq scrambler works as desired\n",
    "test = df_classify['min_toehold_sequence'].iloc[0]\n",
    "print('original sequence:', test)\n",
    "s = seq_scrambler(test)\n",
    "print('scrambled original sequence:', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to simulate many trials of a sklearn model\n",
    "def simulate_sklearn_model(df_classify, ngram_size, ngram_stride, model, model_params, num_trials = 5):\n",
    "    \"\"\"\n",
    "    Function to simulate a scikit-learn Tf-idf classifier.\n",
    "    \n",
    "    Inputs:\n",
    "    df_classify: df that contains a column called 'min_toehold_sequence' and 'quartile_rating'\n",
    "                'min_toehold_sequence': str which is the minimal toehold sequence of length 59 nt\n",
    "                'quartile_rating': integer encoded label to classify the top25% vs. the bottom 75%\n",
    "    ngram_size: int\n",
    "    ngram_stride: int\n",
    "    model: scikit-learn model object\n",
    "    model_params: dict - model_params to run a grid-search \n",
    "    num_trials: int - number of times to repeat the process\n",
    "    \"\"\"\n",
    "    # convert the toehold sequence into a sentence of kmers \n",
    "    df_classify['toehold_sentence'] = df_classify['min_toehold_sequence'].apply(lambda p: seq_sentence(seq=p, ngram_size=ngram_size, ngram_stride=ngram_stride))\n",
    "    # get a list of all toeholds\n",
    "    toeholds = df_classify['min_toehold_sequence'].values.tolist()\n",
    "    # scramble these sequences \n",
    "    scr_toes = [seq_scrambler(seq = p) for p in toeholds]\n",
    "    # turn these scrambled seqs into sentences \n",
    "    scr_toes_sent = [seq_sentence(seq=p, ngram_size=ngram_size, ngram_stride=ngram_stride) for p in scr_toes]\n",
    "    df_classify['scrambled_sentence'] = scr_toes_sent\n",
    "    \n",
    "    # define the training and testing arrays\n",
    "    X = df_classify['toehold_sentence']\n",
    "    X_control = df_classify['scrambled_sentence']\n",
    "    y = df_classify['quartile_rating']\n",
    "    \n",
    "    skf = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 5)\n",
    "    scoring_dict = {'MCC': make_scorer(mcc, greater_is_better = True)}\n",
    "    # create empty lists for the metrics to be saved\n",
    "    mccs = []\n",
    "    accs = []\n",
    "    aucs = []\n",
    "    \n",
    "    mccs_control = []\n",
    "    accs_control = []\n",
    "    aucs_control = []\n",
    "    ngram_sizes = []\n",
    "    ngram_strides = []\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        \n",
    "        # split into training and testing sets\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, stratify = y)\n",
    "        \n",
    "        # tf-idf transform the training set, considering unigrams and bigrams only\n",
    "        tfidf_vec = TfidfVectorizer(lowercase = False, ngram_range = (1,2), analyzer = 'word')\n",
    "        x_train_idf = tfidf_vec.fit_transform(x_train)\n",
    "        # transform the test set similarly\n",
    "        x_test_idf = tfidf_vec.transform(x_test)\n",
    "        # transform the control set similarly\n",
    "        x_control_idf = tfidf_vec.transform(X_control)\n",
    "        \n",
    "        clf = GridSearchCV(model, param_grid = model_params, scoring = scoring_dict, n_jobs = -1, cv = skf, refit = 'MCC',\n",
    "                       return_train_score = False)\n",
    "        clf.fit(x_train_idf, y_train)\n",
    "        clf_best = clf.best_estimator_\n",
    "    \n",
    "        # evaluate on test and control sets\n",
    "        accs.append(clf_best.score(x_test_idf, y_test)) \n",
    "        accs_control.append(clf_best.score(x_control_idf, y))\n",
    "        \n",
    "        y_pred = clf_best.predict(x_test_idf)\n",
    "        y_pred_cont = clf_best.predict(x_control_idf)\n",
    "        \n",
    "        mccs.append(mcc(y_test, y_pred))\n",
    "        mccs_control.append(mcc(y, y_pred_cont))\n",
    "        \n",
    "        y_proba = clf_best.predict_proba(x_test_idf)\n",
    "        y_cont_proba = clf_best.predict_proba(x_control_idf)\n",
    "        \n",
    "        aucs.append(roc_auc_score(y_test, y_proba[:,1]))\n",
    "        aucs_control.append(roc_auc_score(y, y_cont_proba[:,1]))\n",
    "        \n",
    "        ngram_sizes.append(ngram_size)\n",
    "        ngram_strides.append(ngram_stride)\n",
    "\n",
    "    df_eval = pd.DataFrame()\n",
    "    df_eval['test accuracy'] = accs\n",
    "    df_eval['test roc_auc'] = aucs\n",
    "    df_eval['test mcc'] = mccs\n",
    "    df_eval['scrambled accuracy'] = accs_control\n",
    "    df_eval['scrambled roc_auc'] = aucs_control\n",
    "    df_eval['scrambled mcc'] = mccs_control\n",
    "    df_eval['ngram_size'] = ngram_sizes\n",
    "    df_eval['ngram_strides'] = ngram_strides\n",
    "    \n",
    "    return df_eval, clf_best\n",
    "\n",
    "def get_model_lc(df_classify, model, ngram_size, ngram_stride, title):\n",
    "    \"\"\"\n",
    "    Function that plots the learning curve for a scikit-learn tf-idf model.\n",
    "    \n",
    "    df_classify: df that contains a column called 'min_toehold_sequence' and 'quartile_rating'\n",
    "                'min_toehold_sequence': str which is the minimal toehold sequence of length 59 nt\n",
    "                'quartile_rating': integer encoded label to classify the top25% vs. the bottom 75%\n",
    "    ngram_size: int\n",
    "    ngram_stride: int\n",
    "    model: pre-trained scikit-learn model object\n",
    "    title: str - model name\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = False)\n",
    "    train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "    \n",
    "    # convert the toehold sequence into a sentence of kmers \n",
    "    df_classify['toehold_sentence'] = df_classify['min_toehold_sequence'].apply(lambda p: seq_sentence(seq=p, ngram_size=ngram_size, ngram_stride=ngram_stride))\n",
    "    # get a list of all toeholds\n",
    "    toeholds = df_classify['min_toehold_sequence'].values.tolist()\n",
    "    # scramble these sequences \n",
    "    scr_toes = [seq_scrambler(seq = p) for p in toeholds]\n",
    "    # turn these scrambled seqs into sentences \n",
    "    scr_toes_sent = [seq_sentence(seq=p, ngram_size=ngram_size, ngram_stride=ngram_stride) for p in scr_toes]\n",
    "    df_classify['scrambled_sentence'] = scr_toes_sent\n",
    "    \n",
    "    # define the training and testing arrays\n",
    "    X = df_classify['toehold_sentence']\n",
    "    X_control = df_classify['scrambled_sentence']\n",
    "    y = df_classify['quartile_rating']\n",
    "    \n",
    "    # tf-idf transform the training set, considering unigrams and bigrams only\n",
    "    tfidf_vec = TfidfVectorizer(lowercase = False, ngram_range = (1,2), analyzer = 'word')\n",
    "    X_idf = tfidf_vec.fit_transform(X)\n",
    "    # clone the pre-trained model with just the optimized parameters\n",
    "    estimator = clone(model, safe = True)\n",
    "    mcc_scorer = make_scorer(mcc, greater_is_better=True)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Matthews Corr. Coeff\")\n",
    "    train_sizes, _, test_scores = learning_curve(\n",
    "        estimator, X_idf, y, cv = skf, n_jobs = -1, train_sizes = train_sizes, scoring = mcc_scorer, shuffle = False)\n",
    "    \n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"b\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color = \"b\",\n",
    "             label = \"Test MCC\")\n",
    "\n",
    "    plt.legend(loc = \"best\")\n",
    "    \n",
    "    return test_scores_mean, test_scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a naive-bayes model\n",
    "\n",
    "model = MultinomialNB()\n",
    "model_params = {\n",
    "    'alpha':np.linspace(0.0,1.0,10),\n",
    "    'fit_prior': [True]\n",
    "}\n",
    "\n",
    "ngram_sizes = np.linspace(2,6,5).astype(int)\n",
    "df_mnb_results = pd.DataFrame()\n",
    "for ngram in ngram_sizes:\n",
    "    # set both the stride and size to the same\n",
    "    ngram_stride = ngram\n",
    "    ngram_size = ngram\n",
    "    df_eval, _ = simulate_sklearn_model(df_classify = df_classify, \n",
    "                                        ngram_size = ngram_size, \n",
    "                                        ngram_stride = ngram_stride, \n",
    "                                        model = model, \n",
    "                                        model_params = model_params, \n",
    "                                        num_trials = 5)\n",
    "    df_mnb_results = pd.concat([df_mnb_results, df_eval], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at model performance on test set \n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize = (16,4))\n",
    "sns.barplot(x = 'ngram_size', y = 'test mcc', data = df_mnb_results, ax = axs[0], capsize = 0.2)\n",
    "axs[0].set_xlabel('kmer size (nt)')\n",
    "axs[0].set_ylabel('Matthews corr. coeff')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'test accuracy', data = df_mnb_results, ax = axs[1], capsize = 0.2)\n",
    "axs[1].set_xlabel('kmer size (nt)')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'test roc_auc', data = df_mnb_results, ax = axs[2], capsize = 0.2)\n",
    "axs[2].set_xlabel('kmer size (nt)')\n",
    "axs[2].set_ylabel('ROC AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at model performance on scrambled sequences \n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize = (16,4))\n",
    "sns.barplot(x = 'ngram_size', y = 'scrambled mcc', data = df_mnb_results, ax = axs[0], capsize = 0.2)\n",
    "axs[0].set_xlabel('kmer size (nt)')\n",
    "axs[0].set_ylabel('Matthews corr. coeff')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'scrambled accuracy', data = df_mnb_results, ax = axs[1], capsize = 0.2)\n",
    "axs[1].set_xlabel('kmer size (nt)')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'scrambled roc_auc', data = df_mnb_results, ax = axs[2], capsize = 0.2)\n",
    "axs[2].set_xlabel('kmer size (nt)')\n",
    "axs[2].set_ylabel('ROC AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be consistent with language model performance, we will use a 3-mer \n",
    "\n",
    "# train a NB model with a kmer-size of 3 and get the best model\n",
    "model = MultinomialNB()\n",
    "model_params = {\n",
    "    'alpha':np.linspace(0.0,1.0,20),\n",
    "    'fit_prior': [True]\n",
    "}\n",
    "\n",
    "_, clf_best_nb = simulate_sklearn_model(df_classify = df_classify, \n",
    "                                        ngram_size = 3, \n",
    "                                        ngram_stride = 3, \n",
    "                                        model = model, \n",
    "                                        model_params = model_params, \n",
    "                                        num_trials = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curve for the corresponding model and the test-scores are returned for each function\n",
    "tsm_nb, tsd_nb = get_model_lc(df_classify = df_classify, \n",
    "                             model = clf_best_nb, \n",
    "                             ngram_size = 3, \n",
    "                             ngram_stride = 3,\n",
    "                             title = 'Naive-Bayes Tf-iDF Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a logistic regression model \n",
    "\n",
    "model = LogisticRegression()\n",
    "model_params = {\n",
    "        'penalty': [\"l1\", \"l2\", \"elasticnet\"],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10.],\n",
    "        'max_iter': [100],\n",
    "        'n_jobs': [-1],\n",
    "        'class_weight': [\"balanced\"],\n",
    "        'solver': ['sag']\n",
    "}\n",
    "\n",
    "ngram_sizes = np.linspace(2,6,5).astype(int)\n",
    "df_lr_results = pd.DataFrame()\n",
    "for ngram in ngram_sizes:\n",
    "    # set both the stride and size to the same\n",
    "    ngram_stride = ngram\n",
    "    ngram_size = ngram\n",
    "    df_eval, _ = simulate_sklearn_model(df_classify = df_classify, \n",
    "                                        ngram_size = ngram_size, \n",
    "                                        ngram_stride = ngram_stride, \n",
    "                                        model = model, \n",
    "                                        model_params = model_params, \n",
    "                                        num_trials = 5)\n",
    "    df_lr_results = pd.concat([df_lr_results, df_eval], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at model performance on test set \n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize = (16,4))\n",
    "sns.barplot(x = 'ngram_size', y = 'test mcc', data = df_lr_results, ax = axs[0], capsize = 0.2)\n",
    "axs[0].set_xlabel('kmer size (nt)')\n",
    "axs[0].set_ylabel('Matthews corr. coeff')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'test accuracy', data = df_lr_results, ax = axs[1], capsize = 0.2)\n",
    "axs[1].set_xlabel('kmer size (nt)')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'test roc_auc', data = df_lr_results, ax = axs[2], capsize = 0.2)\n",
    "axs[2].set_xlabel('kmer size (nt)')\n",
    "axs[2].set_ylabel('ROC AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at model performance on scrambled sequences \n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize = (16,4))\n",
    "sns.barplot(x = 'ngram_size', y = 'scrambled mcc', data = df_lr_results, ax = axs[0], capsize = 0.2)\n",
    "axs[0].set_xlabel('kmer size (nt)')\n",
    "axs[0].set_ylabel('Matthews corr. coeff')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'scrambled accuracy', data = df_lr_results, ax = axs[1], capsize = 0.2)\n",
    "axs[1].set_xlabel('kmer size (nt)')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'scrambled roc_auc', data = df_lr_results, ax = axs[2], capsize = 0.2)\n",
    "axs[2].set_xlabel('kmer size (nt)')\n",
    "axs[2].set_ylabel('ROC AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a logistic regression model with a kmer size of 3\n",
    "model = LogisticRegression()\n",
    "model_params = {\n",
    "        'penalty': [\"l1\", \"l2\", \"elasticnet\"],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10.],\n",
    "        'max_iter': [10],\n",
    "        'n_jobs': [-1],\n",
    "        'class_weight': [\"balanced\"],\n",
    "        'solver': ['sag']\n",
    "}\n",
    "\n",
    "_, clf_best_lr = simulate_sklearn_model(df_classify = df_classify, \n",
    "                                        ngram_size = 3, \n",
    "                                        ngram_stride = 3, \n",
    "                                        model = model, \n",
    "                                        model_params = model_params, \n",
    "                                        num_trials = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curve for the corresponding model and the test-scores are returned for each function\n",
    "tsm_lr, tsd_lr = get_model_lc(df_classify = df_classify, \n",
    "                             model = clf_best_lr, \n",
    "                             ngram_size = 3, \n",
    "                             ngram_stride = 3,\n",
    "                             title = 'Logistic Regression Tf-iDF Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a random-forest model \n",
    "model_params = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_features': [\"auto\", \"log2\", None],\n",
    "        'min_samples_leaf':  [2,3,4],\n",
    "        'n_jobs': [-1],\n",
    "        'class_weight': [\"balanced\"],\n",
    "        'ccp_alpha': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(verbose = 0)\n",
    "\n",
    "ngram_sizes = np.linspace(2,6,5).astype(int)\n",
    "\n",
    "df_rf_results = pd.DataFrame()\n",
    "for ngram in ngram_sizes:\n",
    "    # set both the stride and size to the same\n",
    "    ngram_stride = ngram\n",
    "    ngram_size = ngram\n",
    "    df_eval, _ = simulate_sklearn_model(df_classify = df_classify, \n",
    "                                        ngram_size = ngram_size, \n",
    "                                        ngram_stride = ngram_stride, \n",
    "                                        model = model, \n",
    "                                        model_params = model_params, \n",
    "                                        num_trials = 5)\n",
    "    df_rf_results = pd.concat([df_rf_results, df_eval], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at model performance on test set \n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize = (16,4))\n",
    "sns.barplot(x = 'ngram_size', y = 'test mcc', data = df_rf_results, ax = axs[0], capsize = 0.2)\n",
    "axs[0].set_xlabel('kmer size (nt)')\n",
    "axs[0].set_ylabel('Matthews corr. coeff')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'test accuracy', data = df_rf_results, ax = axs[1], capsize = 0.2)\n",
    "axs[1].set_xlabel('kmer size (nt)')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'test roc_auc', data = df_rf_results, ax = axs[2], capsize = 0.2)\n",
    "axs[2].set_xlabel('kmer size (nt)')\n",
    "axs[2].set_ylabel('ROC AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at model performance on scrambled sequences \n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize = (16,4))\n",
    "sns.barplot(x = 'ngram_size', y = 'scrambled mcc', data = df_rf_results, ax = axs[0], capsize = 0.2)\n",
    "axs[0].set_xlabel('kmer size (nt)')\n",
    "axs[0].set_ylabel('Matthews corr. coeff')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'scrambled accuracy', data = df_rf_results, ax = axs[1], capsize = 0.2)\n",
    "axs[1].set_xlabel('kmer size (nt)')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "\n",
    "sns.barplot(x = 'ngram_size', y = 'scrambled roc_auc', data = df_rf_results, ax = axs[2], capsize = 0.2)\n",
    "axs[2].set_xlabel('kmer size (nt)')\n",
    "axs[2].set_ylabel('ROC AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_features': [\"auto\", \"log2\", None],\n",
    "        'min_samples_leaf':  [2,3,4],\n",
    "        'n_jobs': [-1],\n",
    "        'class_weight': [\"balanced\"],\n",
    "        'ccp_alpha': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(verbose = 0)\n",
    "\n",
    "_, clf_best_rf = simulate_sklearn_model(df_classify = df_classify, \n",
    "                                        ngram_size = 3, \n",
    "                                        ngram_stride = 3, \n",
    "                                        model = model, \n",
    "                                        model_params = model_params, \n",
    "                                        num_trials = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curve for the corresponding model and the test-scores are returned for each function\n",
    "tsm_rf, tsd_rf = get_model_lc(df_classify = df_classify, \n",
    "                             model = clf_best_rf, \n",
    "                             ngram_size = 3, \n",
    "                             ngram_stride = 3,\n",
    "                             title = 'Random Forest Tf-iDF Model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
